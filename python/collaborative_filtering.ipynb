{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict,Text\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "import duckdb\n",
    "con = duckdb.connect('database.db')\n",
    "\n",
    "#PREPARE DATA\n",
    "\n",
    "podcast_ratings_query = con.sql(\"select author_id as user_id, podcasts.title as podcast_title,rating from reviews \"+ \n",
    "        \"join categories using (podcast_id) \" +\n",
    "        \"join podcasts using (podcast_id) where average_rating >= 0\").to_df()\n",
    "\n",
    "podcast_titles_query = con.sql(\"select podcasts.title as podcast_title from reviews \"+ \n",
    "        \"join categories using (podcast_id) \" +\n",
    "        \"join podcasts using (podcast_id) where average_rating >= 0\").to_df()\n",
    "\n",
    "podcast_ratings = podcast_ratings_query.to_dict(orient='records')\n",
    "podcast_titles = podcast_titles_query.to_dict(orient='records')\n",
    "podcast_ratings_tf = tf.data.Dataset.from_tensor_slices(pd.DataFrame.from_dict(podcast_ratings).to_dict(orient=\"list\"))\n",
    "podcast_titles_tf = tf.data.Dataset.from_tensor_slices(pd.DataFrame.from_dict(podcast_titles).to_dict(orient=\"list\"))\n",
    "\n",
    "ratings_tf = podcast_ratings_tf.map(lambda x: {\n",
    "    \"podcast_title\": x[\"podcast_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"rating\"]\n",
    "})\n",
    "titles_tf = podcast_titles_tf.map(lambda x: x[\"podcast_title\"])\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings_tf.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train_len = int(len(shuffled) * (2/3))\n",
    "test_len = int(len(shuffled) - train_len)\n",
    "\n",
    "train = shuffled.take(train_len)\n",
    "test = shuffled.skip(train_len).take(test_len)\n",
    "\n",
    "podcast_titles = titles_tf.batch(1_000)\n",
    "user_ids = ratings_tf.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_podcast_titles = np.unique(np.concatenate(list(podcast_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 79ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0156 - factorized_top_k/top_100_categorical_accuracy: 0.0312 - loss: 1064.6252 - regularization_loss: 0.0000e+00 - total_loss: 1064.6252\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 83ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0136 - factorized_top_k/top_10_categorical_accuracy: 0.0429 - factorized_top_k/top_50_categorical_accuracy: 0.1404 - factorized_top_k/top_100_categorical_accuracy: 0.3509 - loss: 1059.1138 - regularization_loss: 0.0000e+00 - total_loss: 1059.1138\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 68ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0078 - factorized_top_k/top_10_categorical_accuracy: 0.0468 - factorized_top_k/top_50_categorical_accuracy: 0.2047 - factorized_top_k/top_100_categorical_accuracy: 0.4639 - loss: 1028.1071 - regularization_loss: 0.0000e+00 - total_loss: 1028.1071\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 63ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0058 - factorized_top_k/top_10_categorical_accuracy: 0.0487 - factorized_top_k/top_50_categorical_accuracy: 0.2417 - factorized_top_k/top_100_categorical_accuracy: 0.5029 - loss: 960.3350 - regularization_loss: 0.0000e+00 - total_loss: 960.3350\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 59ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0136 - factorized_top_k/top_10_categorical_accuracy: 0.0546 - factorized_top_k/top_50_categorical_accuracy: 0.2573 - factorized_top_k/top_100_categorical_accuracy: 0.5088 - loss: 879.8532 - regularization_loss: 0.0000e+00 - total_loss: 879.8532\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 65ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0234 - factorized_top_k/top_10_categorical_accuracy: 0.0663 - factorized_top_k/top_50_categorical_accuracy: 0.2651 - factorized_top_k/top_100_categorical_accuracy: 0.5107 - loss: 813.1013 - regularization_loss: 0.0000e+00 - total_loss: 813.1013\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 67ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0273 - factorized_top_k/top_10_categorical_accuracy: 0.0760 - factorized_top_k/top_50_categorical_accuracy: 0.2710 - factorized_top_k/top_100_categorical_accuracy: 0.5127 - loss: 761.6284 - regularization_loss: 0.0000e+00 - total_loss: 761.6284\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 65ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0292 - factorized_top_k/top_10_categorical_accuracy: 0.0838 - factorized_top_k/top_50_categorical_accuracy: 0.2749 - factorized_top_k/top_100_categorical_accuracy: 0.5127 - loss: 724.3841 - regularization_loss: 0.0000e+00 - total_loss: 724.3841\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0312 - factorized_top_k/top_10_categorical_accuracy: 0.0858 - factorized_top_k/top_50_categorical_accuracy: 0.2749 - factorized_top_k/top_100_categorical_accuracy: 0.5127 - loss: 700.5828 - regularization_loss: 0.0000e+00 - total_loss: 700.5828\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 66ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0312 - factorized_top_k/top_10_categorical_accuracy: 0.0858 - factorized_top_k/top_50_categorical_accuracy: 0.2749 - factorized_top_k/top_100_categorical_accuracy: 0.5127 - loss: 686.0484 - regularization_loss: 0.0000e+00 - total_loss: 686.0484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.Streaming at 0x1ae14bb3f40>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAIN MODEL\n",
    "\n",
    "class PodcastlensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "    self.user_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_user_ids, mask_token=None),\n",
    "      # We add an additional embedding to account for unknown tokens.\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    self.podcast_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_podcast_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_podcast_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    metrics = tfrs.metrics.FactorizedTopK(\n",
    "      candidates=titles_tf.batch(128).map(self.podcast_model)\n",
    "    )\n",
    "\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "      metrics=metrics\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the podcast features and pass them into the podcast model,\n",
    "    # getting embeddings back.\n",
    "    positive_podcast_embeddings = self.podcast_model(features[\"podcast_title\"])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(user_embeddings, positive_podcast_embeddings)\n",
    "\n",
    "model = PodcastlensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "cached_train = train.shuffle(50_000).batch(512).cache()\n",
    "cached_test = test.batch(256).cache()\n",
    "model.fit(cached_train, epochs=10)\n",
    "\n",
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.Streaming(model.user_model,k=20)\n",
    "# recommends podcasts out of the entire podcasts dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((titles_tf.batch(100), titles_tf.batch(100).map(model.podcast_model)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 72ms/step - factorized_top_k/top_1_categorical_accuracy: 0.5642 - factorized_top_k/top_5_categorical_accuracy: 0.5681 - factorized_top_k/top_10_categorical_accuracy: 0.5798 - factorized_top_k/top_50_categorical_accuracy: 0.6381 - factorized_top_k/top_100_categorical_accuracy: 0.6732 - loss: 335.9823 - regularization_loss: 0.0000e+00 - total_loss: 335.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.5642023086547852,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.5680933594703674,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.5797665119171143,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.6381322741508484,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.6731517314910889,\n",
       " 'loss': 0.0,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 0.0}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PULL METRICS FOR MODEL ON TEST DATA\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user d366ab241d287f1: ['Daily Solutions Podcast', 'New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)', 'Things a Teacher Taught Me']\n",
      "\n",
      "Recommendations for user dee9d0248349ff8: ['Nahh B! Podcast MMA / UFC And Boxing Event Preview & Reviews', 'Tall Tale TV', 'The Daily Boost | Daily Coaching and Motivation', 'Understanding Human Behavior - Video']\n",
      "\n",
      "Recommendations for user e40b9193f15f266: ['New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)', 'Things a Teacher Taught Me', 'Twin Talk with the King Twins']\n",
      "\n",
      "Recommendations for user e40b9193f15f266: ['New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)', 'Things a Teacher Taught Me', 'Twin Talk with the King Twins']\n",
      "\n",
      "Recommendations for user 42ded2f5c6d7ac3: ['Her Money Matters', 'Nahh B! Podcast MMA / UFC And Boxing Event Preview & Reviews', 'Tall Tale TV']\n",
      "\n",
      "Recommendations for user cc8ea26c6e0dcbc: ['Nahh B! Podcast MMA / UFC And Boxing Event Preview & Reviews', 'Talking Web Marketing', 'The Oatley Academy ArtCast']\n",
      "\n",
      "Recommendations for user e40b9193f15f266: ['New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)', 'Things a Teacher Taught Me', 'Twin Talk with the King Twins']\n",
      "\n",
      "Recommendations for user 07fa2c80fbd844a: ['All of the Above radio', 'Little Realms | A DnD Actual Play Podcast', 'Sketched Out']\n",
      "\n",
      "Recommendations for user 2a54e87ac1ea627: ['Daily Solutions Podcast', 'New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)', 'Things a Teacher Taught Me']\n",
      "\n",
      "Recommendations for user 9921a8082017b83: ['Daily Solutions Podcast', 'New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)', 'Things a Teacher Taught Me']\n",
      "\n",
      "Recommendations for user fb6ca03240db301: ['Hear It Now (retired)', 'NFL no ProFootballcast com Antony Curti e Eduardo Miceli', 'Talking Web Marketing']\n",
      "\n",
      "Recommendations for user fb6ca03240db301: ['Hear It Now (retired)', 'NFL no ProFootballcast com Antony Curti e Eduardo Miceli', 'Talking Web Marketing']\n",
      "\n",
      "Recommendations for user 1bef95c9c0016c1: ['In Real Life with Emily and Kimzilla | WFMU', 'Lost In The Shuffle', 'Nahh B! Podcast MMA / UFC And Boxing Event Preview & Reviews', 'Understanding Human Behavior - Video']\n",
      "\n",
      "Recommendations for user 8257864fff0515d: ['Little Realms | A DnD Actual Play Podcast', 'The Fertility Warriors Podcast: Helping women survive infertility and trying to conceive', 'Understanding Human Behavior - Video']\n",
      "\n",
      "Recommendations for user 3dec76c7d97bf1e: ['All of the Above radio', 'I Crush Barbecue Show', 'Last Week at the Movies Podcast', 'Things a Teacher Taught Me']\n",
      "\n",
      "Recommendations for user 6da3f0a453e510d: ['All of the Above radio', 'I Crush Barbecue Show', 'New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)']\n",
      "\n",
      "Recommendations for user c73af151b7104ef: ['Daily Solutions Podcast', 'New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)', 'Things a Teacher Taught Me', 'Twin Talk with the King Twins']\n",
      "\n",
      "Recommendations for user 42ded2f5c6d7ac3: ['Her Money Matters', 'Nahh B! Podcast MMA / UFC And Boxing Event Preview & Reviews', 'Tall Tale TV']\n",
      "\n",
      "Recommendations for user 6d6537f2e73caef: ['New Patient Group™ (Formally known as the Doctor Diamond Club Podcast)', 'Things a Teacher Taught Me', 'Twin Talk with the King Twins']\n",
      "\n",
      "Recommendations for user 42ded2f5c6d7ac3: ['Her Money Matters', 'Nahh B! Podcast MMA / UFC And Boxing Event Preview & Reviews', 'Tall Tale TV']\n",
      "\n",
      "Recommendations for user 7d81a726ea553c0: ['I Crush Barbecue Show', 'Lost In The Shuffle', 'Nahh B! Podcast MMA / UFC And Boxing Event Preview & Reviews', 'Things a Teacher Taught Me', 'Understanding Human Behavior - Video']\n",
      "\n",
      "Recommendations for user e3713d1d11c289a: ['All of the Above radio', 'In Real Life with Emily and Kimzilla | WFMU', 'Lost In The Shuffle']\n",
      "\n",
      "Recommendations for user b3dd55b0f6dea86: ['Lost In The Shuffle', 'Nahh B! Podcast MMA / UFC And Boxing Event Preview & Reviews', 'Sketched Out', 'Tall Tale TV', 'Understanding Human Behavior - Video']\n",
      "\n",
      "Recommendations for user cf795f180f1865d: ['F*ck Like a Woman', 'Maximiza Tu Negocio en Redes de Mercadeo', 'Talking Web Marketing']\n",
      "\n",
      "Number of users with more than 2 recommendation: 24\n"
     ]
    }
   ],
   "source": [
    "#RUN PREDICTIONS ON TEST DATA\n",
    "num = 0\n",
    "threshold = 2\n",
    "for element in test:\n",
    "    user_id = element[\"user_id\"].numpy().decode()\n",
    "    _, titles = index(tf.constant([user_id]))\n",
    "    unique_preds = np.unique(titles.numpy())\n",
    "    unique_preds = [el.decode('UTF-8') for el in unique_preds]\n",
    "    if len(unique_preds) > threshold:\n",
    "        print(\"Recommendations for user {}: {}\".format(user_id,unique_preds))\n",
    "        print(\"\")\n",
    "        num += 1\n",
    "print(\"Number of users with more than {} recommendation: {}\".format(threshold,num))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
